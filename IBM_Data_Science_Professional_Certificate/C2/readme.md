# Tools for Data Science

Learning goals for the course

In this course you will be introduced to a Data Scientist's workbench or toolkit that consists of a variety of tools, languages, libraries, APIs, data sets, models, etc. used by Data Scientists. Try not to be overwhelmed by the sheer number of components and tools that exist in the Data Science ecosystem. The main goal of the course is for you to be knowledgeable about the kinds of tools Data Scientists use, their examples, and get some hands-on time with a few key tools. 

As such, you are not required to recall the name of every single tool covered in the course. However, be familiar with the categories or types of tools and 1 or 2 examples each type. Modules 4 and 5 of this course will cover some of the most important ones for a beginner Data Scientist in greater depth and enable you to get hands-on experience with them. As you take additional Data Science courses, you will become more acquainted with some of the other tools and libraries. Some may be required to perform more specialized or advanced Data Science or Machine Learning tasks. So don't try to remember all of the names just now. Pay special attention, though, to Video and Lesson summaries.

To successfully complete the course, you are required to complete the first 6 out of the 7 modules in the course. The 7th module is an optional one.

Here is what you will be learning in each module:

**Module 1: Overview of Data Science Tools**

In this module, you will learn about the different types and categories of tools that data scientists use and popular examples of each. You will also become familiar with Open Source,  Cloud-based,  and Commercial options for data science tools.

    Describe the components of a Data Scientist's toolkit and list various tool categories

    List examples of Open Source, Commercial, and Cloud-based tools in various categories

**Module 2: Languages of Data Science**

This module will bring awareness about the criteria determining which language you should learn. You will learn the benefits of Python, R, SQL, and other common languages such as Java, Scala, C++, JavaScript, and Julia. You will explore how you can use these languages in Data Science. You will also look at some sites for more information about the languages. 
Learning Objectives

    Identify the criteria and roles for determining the language to learn.

    Identify the users and benefits of Python.

    Identify the users and uses of the R language.

    Define SQL elements and list their benefits.

    Review languages such as Java, Scala, C++, JavaScript, and Julia.

    List the global communities for connecting with other users.

**Module 3: Packages, APIs, Data Sets and Models**

This module will give you in-depth knowledge of different libraries, APIs, dataset sources and models used by data scientist.

Learning Objectives

    List examples of the various libraries: scientific, visualization, machine learning, and deep learning.

    Define REST API to request and respond.

    Describe data sets and sources of data.

    Explore open data sets on the Data Asset eXchange.

    Describe how to use a learning model to solve a problem.

    List the tasks that a data scientist needs to perform to build a model.

    Explore ML models in the Model Learning eXchange.

**Module 4: Jupyter Notebooks and JupyterLab**

This module introduces the Jupyter Notebook and JupyterLab. You will learn how to work with different kernels and the basic Jupyter architecture. In addition, you will identify the tools in an Anaconda Jupyter environment. Finally, the module overviews cloud-based Jupyter environments and their data science features. 

Learning Objectives

    Describe how to use the notebooks in JupyterLab.

    Describe how to work in a notebook session.

    Describe the basic Jupyter architecture.

    Describe how to work with kernels.

    Identify tools in Anaconda Jupyter environments.

    Describe cloud-based Jupyter environments and their data science features.

**Module 5: RStudio and GitHub**

This module will start with an introduction to R and RStudio and will end up with Github usage. You will learn about the different R visualization packages and how to create visual charts using the plot function.

Further in the module, you will develop the essential conceptual and hands-on skills to work with Git and GitHub. You will start with an overview of Git and GitHub, creating a GitHub account and a project repository, adding files, and committing your changes using the web interface. Next, you will become familiar with Git workflows involving branches, pull requests (PRs), and merges. You will also complete a project at the end to apply and demonstrate your newly acquired skills. 

Learning Objectives

    Describe R capabilities and RStudio environment.

    Use the inbuilt R plot function.

    Explain version control and describe the Git and GitHub environment.

    Describe the purpose of source repositories and explain how GitHub satisfies the needs of a source repository.

    Create a GitHub account and a project repository.

    Demonstrate how to edit and upload files in GitHub.

    Explain the purpose of branches and how to merge changes.

**Module 6: Final Project and Assessment**

In this module, you will work on a final project to demonstrate some of the skills learned in the course. You will also be tested on your knowledge of various components and tools in a Data Scientist's toolkit learned in the previous modules.

Learning Objectives

    Create a Jupyter Notebook with markdown and code cells

    List examples of languages, libraries and tools used in Data Science

    Share your Jupyter Notebook publicly on GitHub

    Evaluate notebooks submitted by your peers using the provided rubric

    Demonstrate proficiency in Data Science toolkit knowledge

**Module7: IBM Watson Studio**

This is as an optional module if you are interested in learning about and working with data science tools from IBM such as  Watson Studio.
Learning Objectives

    Find common resources in Watson Studio and IBM Cloud Pak for Data.

    Create an IBM Cloud account, service, and project in Watson Studio.

    Create and share a Jupyter Notebook.

    Use different types of Jupyter Notebook templates and kernels on IBM Watson Studio.

    Describe how to connect a Watson Studio account and publish a notebook in GitHub.

## Data Science Tools
[Open Source Tools for Data Science](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0130EN-SkillsNetwork/storyline/Open%20Source%20Tools/story.html?origin=www.coursera.org)

### Data Science Task Categories
- Data Management: MySQL, Postgress, mongoDB, CouchDB, Cassandra, Handoop, Ceph, ElasticSearch,...
- Data Integration and Transformation (ETL): Aphace Kafka, Apache Airflow, Kubeflow, Aphace Spark SQL, Aphace Nifi, NodeRED,...
- Data Visualization: PixelDust, HUE, Kibana, Superset,...
- Model Bulding
- Model Deployment: PredictionIO, SelDon, mleap, Tensorflow-Serving, Tensorflow-Lite, Tensorflow.JS,...
- Model Monitoring and Assessment: ModelDB, Prometheus,...

### Data Science Task supported by
- Execution Environments: ApacheSpark, ApacheFlink, 
- Data Asset Management: ApacheAtlas, EGERIA, Kylo,...
- Code Asset Management: Git, GitLab, GitHub, Bitbucket,...
- Development Environments (IDEs): Jupyter Notebook, JypyterLab, ApacheZeppelin, RStudio, Spyder,...

## Languages of Data Science

You should select a language to learn depending on your needs, the problems you are trying to solve, and whom you are solving them for.

The popular languages are Python, R, SQL, Scala, Java, C++, and Julia.

For data science, you can use Python's scientific computing libraries like Pandas, NumPy, SciPy, and Matplotlib. 

Python can also be used for Natural Language Processing (NLP) using the Natural Language Toolkit (NLTK). 

Python is open source, and R is free software. 

R language’s array-oriented syntax makes it easier to translate from math to code for learners with no or minimal programming background.

SQL is different from other software development languages because it is a non-procedural language.

SQL was designed for managing data in relational databases. 

If you learn SQL and use it with one database, you can apply your SQL knowledge with many other databases easily.

Data science tools built with Java include Weka, Java-ML, Apache MLlib, and Deeplearning4.

For data science, popular program built with Scala is Apache Spark which includes Shark, MLlib, GraphX, and Spark Streaming.

Programs built for Data Science with JavaScript include TensorFlow.js and R-js.

One great application of Julia for Data Science is JuliaDB.

## Libraries APIs, Datasets and Models

API is the part of the library you see while the library contains all the components of the program. 

REST APIs allow you to communicate through the internet and take advantage of resources like storage, data, artificially intelligent algorithms, and much more.

Open data is fundamental to Data Science.

Community Data License Agreement makes it easier to share open data.

The IBM Data Asset eXchange (DAX) site contains high-quality open data sets.

DAX open data sets include tutorial notebooks that provide basic and advanced walk-throughs for developers.

DAX notebooks open in Watson Studio.

Machine learning (ML) uses algorithms – also known as “models” – to identify patterns in the data. 

Types of ML are Supervised, Unsupervised, and Reinforcement. 

Supervised learning comprises two types of models, regression and classification.

Deep learning refers to a general set of models and techniques that loosely emulate the way the human brain solves a wide range of problems.

The Model Asset eXchange is a free, open-source repository for ready-to-use and customizable deep-learning microservices.

MAX model-serving microservices are built and distributed on GitHub as open-source Docker images.

You can use Red Hat OpenShift, a Kubernetes platform, to automate deployment, scaling, and management of microservices.

Ml-exchange.org has multiple predefined models.

[Additional Sources of Datasets](https://author-ide.skills.network/render?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJtZF9pbnN0cnVjdGlvbnNfdXJsIjoiaHR0cHM6Ly9jZi1jb3Vyc2VzLWRhdGEuczMudXMuY2xvdWQtb2JqZWN0LXN0b3JhZ2UuYXBwZG9tYWluLmNsb3VkL0lCTURldmVsb3BlclNraWxsc05ldHdvcmstRFMwMTA1RU4tU2tpbGxzTmV0d29yay9sYWJzL0xhYnNfVjQvQWRkaXRpb25hbF9Tb3VyY2VzX09mX0RhdGFTZXRhLm1kIiwidG9vbF90eXBlIjoiaW5zdHJ1Y3Rpb25hbC1sYWIiLCJhZG1pbiI6ZmFsc2UsImlhdCI6MTcwMDY3MDQ1OX0.s6z0Yoy-xbMDOgN6pkJ9YthPUG96VrvpWOGrqTO8j54)

[DAX](https://developer.ibm.com/exchanges/data/)

[MAX](https://www.ml-exchange.org/models/)

## Jupyter Notebook and JupyterLab

Congratulations! You have completed this module. At this point in the course, you know:

Jupyter Notebooks are used in Data Science for recording experiments and projects.

Jupyter Lab is compatible with many files and Data Science languages.

There are different ways to install and use Jupyter Notebooks.

How to run, delete, and insert a code cell in Jupyter Notebooks.

How to run multiple notebooks at the same time.

How to present a notebook using a combination of Markdown and code cells.

How to shut down your notebook sessions after you have completed your work on them.

Jupyter implements a two-process model with a kernel and a client.

The notebook server is responsible for saving and loading the notebooks.

The kernel executes the cells of code contained in the Notebook. 

The Jupyter architecture uses the NB convert tool to convert files to other formats.

Jupyter implements a two-process model with a kernel and a client.

The Notebook server is responsible for saving and loading the notebooks.

The Jupyter architecture uses the NB convert tool to convert files to other formats.

The Anaconda Navigator GUI can launch multiple applications on a local device.

Jupyter environments in the Anaconda Navigator include JupyterLab and VS Code.

You can download Jupyter environments separately from the Anaconda Navigator, but they may not be configured properly.

The Anaconda Navigator GUI can launch multiple applications.

Additional open-source Jupyter environments include JupyterLab, JupyterLite, VS Code, and Google Colaboratory. 

JupyterLite is a browser-based tool.

## RStudio and GitHub

Congratulations! You have completed this module. At this point in the course, you know:

The capabilities of R and its uses in Data Science.

The RStudio interface for running R codes. 

Popular R packages for Data Science.

Popular data visualization packages in R.

Plotting with the inbuilt R plot function.

Plotting with ggplot.

Adding titles and changing the axis names using the ggtitle and lab’s function.

A Distributed Version Control System (DVCS) keeps track of changes to code, regardless of where it is stored. 

Version control allows multiple users to work on the same codebase or repository, mirroring the codebase on their own computers if needed, while the distributed version control software helps manage synchronization amongst the various codebase mirrors.

Repositories are storage structures that:

    Store the code

    Track issues and changes

    Enable you to collaborate with others

Git is one of the most popular distributed version control systems. 

GitHub, GitLab and Bitbucket are examples of hosted version control systems.

Branches are used to isolate changes to code. When the changes are complete, they can be merged back into the main branch.

Repositories can be cloned to make it possible to work locally, then sync changes back to the original.

[glossary](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0105EN-SkillsNetwork/labs/Labs_V4/Glossary/Glossary.pdf)